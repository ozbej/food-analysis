{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8FwKQRYmrx4"
      },
      "source": [
        "Projekt AIR - Recipe analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0kicAVLnOwV"
      },
      "source": [
        "# 0) data loading, prepreation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDhEbQgc3qrV",
        "outputId": "da7f07e4-0009-4180-cc72-cc031211bf88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘drive’: File exists\n",
            "/content/drive\n",
            "mkdir: cannot create directory ‘MyDrive’: File exists\n",
            "/content\n",
            "/\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ]
        }
      ],
      "source": [
        "#mount google drive\n",
        "# !sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !sudo apt-get update -qq 2>&1 > /dev/null\n",
        "# !sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "# !google-drive-ocamlfuse\n",
        "\n",
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set rand seed\n",
        "SEED = 12345678"
      ],
      "metadata": {
        "id": "lwvBrOYNZ6Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6rpkQC2np-3",
        "outputId": "549dae1b-7316-4345-cf7b-f79c7c05fd40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.8/dist-packages (0.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torcheval) (4.4.0)\n",
            "Requirement already satisfied: torchtnt in /usr/local/lib/python3.8/dist-packages (from torcheval) (0.0.4)\n",
            "Requirement already satisfied: pyre-extensions in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (0.0.30)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (57.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (1.13.0+cu116)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (2022.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (4.64.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (5.9.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (2.9.1)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.8/dist-packages (from pyre-extensions->torchtnt->torcheval) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.6.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.51.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (2.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtnt->torcheval) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->torchtnt->torcheval) (5.2.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (1.24.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect->pyre-extensions->torchtnt->torcheval) (0.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->torchtnt->torcheval) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtnt->torcheval) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install torcheval\n",
        "# imports\n",
        "from torch import nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from numpy.linalg import norm\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast\n",
        "import copy\n",
        "import math\n",
        "\n",
        "# load datasets\n",
        "#recipes          = pd.read_csv('drive/MyDrive/kaggle_recipes/PP_recipes.csv')\n",
        "raw_recipes      = pd.read_csv('/content/drive/MyDrive/kaggle_recipes/RAW_recipes.csv')\n",
        "#ingredient_map   = pd.read_pickle('drive/MyDrive/kaggle_recipes/ingr_map.pkl')\n",
        "raw_interactions = pd.read_csv('/content/drive/MyDrive/kaggle_recipes/RAW_interactions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2597
        },
        "id": "Kzyn3VZY1jnY",
        "outputId": "c598f253-8b8d-431e-9a37-665eded09f2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         name      id  minutes  \\\n",
              "0  arriba   baked winter squash mexican style  137739       55   \n",
              "1  arriba   baked winter squash mexican style  137739       55   \n",
              "\n",
              "   contributor_id   submitted  \\\n",
              "0           47892  2005-09-16   \n",
              "1           47892  2005-09-16   \n",
              "\n",
              "                                                tags  \\\n",
              "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "1  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "\n",
              "                               nutrition  n_steps  \\\n",
              "0  [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
              "1  [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
              "\n",
              "                                               steps  \\\n",
              "0  ['make a choice and proceed with recipe', 'dep...   \n",
              "1  ['make a choice and proceed with recipe', 'dep...   \n",
              "\n",
              "                                         description  \\\n",
              "0  autumn is my favorite time of year to cook! th...   \n",
              "1  autumn is my favorite time of year to cook! th...   \n",
              "\n",
              "                                         ingredients  n_ingredients  user_id  \\\n",
              "0  ['winter squash', 'mexican seasoning', 'mixed ...              7     4470   \n",
              "1  ['winter squash', 'mexican seasoning', 'mixed ...              7   593927   \n",
              "\n",
              "   recipe_id        date  rating  \\\n",
              "0     137739  2006-02-18       5   \n",
              "1     137739  2010-08-21       5   \n",
              "\n",
              "                                              review  \n",
              "0   I used an acorn squash and recipe#137681 Swee...  \n",
              "1  This was a nice change. I used butternut squas...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80fdba1a-ac80-4737-bec9-925e9345c1b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>tags</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>steps</th>\n",
              "      <th>description</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>n_ingredients</th>\n",
              "      <th>user_id</th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>date</th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arriba   baked winter squash mexican style</td>\n",
              "      <td>137739</td>\n",
              "      <td>55</td>\n",
              "      <td>47892</td>\n",
              "      <td>2005-09-16</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
              "      <td>11</td>\n",
              "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
              "      <td>autumn is my favorite time of year to cook! th...</td>\n",
              "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
              "      <td>7</td>\n",
              "      <td>4470</td>\n",
              "      <td>137739</td>\n",
              "      <td>2006-02-18</td>\n",
              "      <td>5</td>\n",
              "      <td>I used an acorn squash and recipe#137681 Swee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>arriba   baked winter squash mexican style</td>\n",
              "      <td>137739</td>\n",
              "      <td>55</td>\n",
              "      <td>47892</td>\n",
              "      <td>2005-09-16</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
              "      <td>11</td>\n",
              "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
              "      <td>autumn is my favorite time of year to cook! th...</td>\n",
              "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
              "      <td>7</td>\n",
              "      <td>593927</td>\n",
              "      <td>137739</td>\n",
              "      <td>2010-08-21</td>\n",
              "      <td>5</td>\n",
              "      <td>This was a nice change. I used butternut squas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80fdba1a-ac80-4737-bec9-925e9345c1b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80fdba1a-ac80-4737-bec9-925e9345c1b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80fdba1a-ac80-4737-bec9-925e9345c1b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# load interactions into recipes\n",
        "recipe_interactions = pd.merge(raw_recipes, raw_interactions, left_on='id', right_on='recipe_id')\n",
        "recipe_interactions.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVfvWjirnPvT"
      },
      "source": [
        "# 1) meal planning / suggestion based on personal taste and diet preferences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iia1Acai_y7p"
      },
      "source": [
        "# Basic data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKIUlN1N__5v"
      },
      "source": [
        "**Rating distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ0pio8onqb0",
        "outputId": "b4304a13-439a-41fc-b428-444908f4b5f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.132367e+06\n",
              "mean     4.411016e+00\n",
              "std      1.264752e+00\n",
              "min      0.000000e+00\n",
              "25%      4.000000e+00\n",
              "50%      5.000000e+00\n",
              "75%      5.000000e+00\n",
              "max      5.000000e+00\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "recipe_interactions['rating'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "6Wy81VhSASHP",
        "outputId": "d60f7444-c5c3-4c1b-da4f-70605c09d5fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f6402d73580>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.displot(recipe_interactions['rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r2vKYtCAuWc"
      },
      "source": [
        "**Correlations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "g-L7UOPFAxOP",
        "outputId": "8fecf900-7120-4fa0-b9ba-4958d273f187"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7d2babaa65e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecipe_interactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'contributor_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recipe_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorr_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recipe_interactions' is not defined"
          ]
        }
      ],
      "source": [
        "corr_data = recipe_interactions.drop(['user_id', 'id', 'contributor_id', 'recipe_id'], axis=1)\n",
        "corr_data.head(2)\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.heatmap(corr_data.corr(), annot=True)\n",
        "\n",
        "# -> minimal (no) correlation between minutes, steps and rating\n",
        "# -> might be different for individual useres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "RR73lqoSDb_B",
        "outputId": "1209a0a6-da39-4e9d-d1dc-f4155f35c4e6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8dab1b0f6879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# expand nutrition data, drop data from before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcorr_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcorr_data_nut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minutes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_ingredients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcorr_data_nut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calories'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total fat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sugar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sodium'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'protein'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'saturated fat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'carbohydrates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoFloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorr_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nutrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'corr_data' is not defined"
          ]
        }
      ],
      "source": [
        "# correlations between nutriton data & rating\n",
        "#corr_data['nutrition'] = corr_data['nutrition'].apply(ast.literal_eval)\n",
        "\n",
        "def toFloat(row):\n",
        "  row[0] = row[0].replace('[', '')\n",
        "  row[-1] = row[-1].replace(']', '')\n",
        "  for i, data in enumerate(row):\n",
        "    row[i] = float(data)\n",
        "  return row\n",
        "\n",
        "# expand nutrition data, drop data from before\n",
        "corr_data.head(2)\n",
        "corr_data_nut = corr_data.drop(['n_steps', 'minutes', 'n_ingredients'], axis=1)\n",
        "corr_data_nut[['calories','total fat','sugar','sodium','protein','saturated fat','carbohydrates']] = [toFloat(row) for row in corr_data['nutrition'].str.split(\",\")]\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.heatmap(corr_data_nut.corr(), annot=True)\n",
        "\n",
        "#-> no correlation between rating and individual ingredients\n",
        "#-> might be different for individual users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0a0sfqXrAxA"
      },
      "source": [
        "**Train & predict tags for recipes, based on description (and nutrition distribution) - later used for recipe querying & recommendation, clustering recipes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "284Nt3S9SV3j"
      },
      "outputs": [],
      "source": [
        "# convert data types\n",
        "data = copy.copy(raw_recipes)\n",
        "data['tags'] = raw_recipes['tags'].apply(ast.literal_eval)\n",
        "data['nutrition'] = raw_recipes['nutrition'].apply(ast.literal_eval)\n",
        "data['ingredients'] = raw_recipes['ingredients'].apply(ast.literal_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQZ6QGpMAULg"
      },
      "source": [
        "**Analyze word count of descriptions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "MMyeoONFAfee",
        "outputId": "bd83d781-06be-4263-e5dd-af772d0914df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5.8192e+04, 6.2163e+04, 4.3155e+04, 2.5456e+04, 1.4958e+04,\n",
              "        8.6350e+03, 5.2350e+03, 3.0920e+03, 1.8970e+03, 1.1590e+03,\n",
              "        8.7000e+02, 5.9000e+02, 3.7800e+02, 2.2300e+02, 1.7300e+02,\n",
              "        1.0600e+02, 9.1000e+01, 5.9000e+01, 5.2000e+01, 3.6000e+01]),\n",
              " array([  1. ,  15.9,  30.8,  45.7,  60.6,  75.5,  90.4, 105.3, 120.2,\n",
              "        135.1, 150. , 164.9, 179.8, 194.7, 209.6, 224.5, 239.4, 254.3,\n",
              "        269.2, 284.1, 299. ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def wordcount(description):\n",
        "  return description.str.count(' ') +1\n",
        "\n",
        "max_description_len = 300\n",
        "\n",
        "data = data.assign(description_words = lambda row: wordcount(row['description']), axis=1)\n",
        "tagged_data = data[data['description_words'] > 0]\n",
        "tagged_data = tagged_data[tagged_data['description_words'] < max_description_len]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.hist(bins=20, x=tagged_data['description_words'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YgdXkokrec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "cbcfcf84-59cf-4d4f-f094-009d82d94cd7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1a57204eadec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlen_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# get top len_tags tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtaglist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtaglist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_occurences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "tag_occurences = {}\n",
        "\n",
        "# initialise tokenizer and model\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2' # TODO: check\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "len_tags = 20\n",
        "# get top len_tags tags\n",
        "for taglist in data['tags']:\n",
        "  for tag in taglist:\n",
        "    if tag not in tag_occurences:\n",
        "      tag_occurences[tag] = 1\n",
        "    else:\n",
        "      tag_occurences[tag] +=1\n",
        "\n",
        "top_tags = dict(sorted(tag_occurences.items(), reverse=True, key=lambda d: d[1])[:len_tags])\n",
        "tag_list = top_tags.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jdd_hP7JmgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "88068f0b-5ced-4f40-d330-0336982e8e79"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c1a58e5a9c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one-hot encode tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# todo: remove most 2 frequent tags, seem to appear in each recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4486\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \"\"\"\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c1a58e5a9c35>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one-hot encode tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# todo: remove most 2 frequent tags, seem to appear in each recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-c1a58e5a9c35>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one-hot encode tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# todo: remove most 2 frequent tags, seem to appear in each recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tag_list' is not defined"
          ]
        }
      ],
      "source": [
        "# one-hot encode tags\n",
        "# todo: remove most 2 frequent tags, seem to appear in each recipe\n",
        "tagged_data = tagged_data.assign(tag_vector = lambda x: [[words_row.count(word) for word in tag_list] for words_row in x['tags']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uO4SWj52KVE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "b8b666ba-780c-4afb-9dc3-7c189663b3c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tag_vector'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-61dcf6e7c668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_DATA_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tag_vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_DATA_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# split data into train + test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tag_vector'"
          ]
        }
      ],
      "source": [
        "# rand seed\n",
        "MAX_DATA_SIZE = 50000 #-> avoid running out of gpu memory\n",
        "# split data\n",
        "test_size = .1\n",
        "validation_size = .2\n",
        "x = tagged_data.head(MAX_DATA_SIZE)\n",
        "y = tagged_data['tag_vector'].head(MAX_DATA_SIZE).values.tolist()\n",
        "# split data into train + test\n",
        "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=test_size, random_state=SEED,shuffle=True)\n",
        "# split train into train + validation\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train, y_train, test_size=validation_size, random_state=SEED,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUWvZYUiTO2R"
      },
      "outputs": [],
      "source": [
        "# tokenize descriptions\n",
        "# create class that reads the text in for BERT\n",
        "class TaggedRecipes (torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tags, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = data['description'].values.tolist()\n",
        "        self.labels = tags\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens = True,\n",
        "            max_length = 300,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        input_ids = inputs['input_ids'].flatten()\n",
        "        attn_mask = inputs['attention_mask'].flatten()\n",
        "        # todo: add token type ids?\n",
        "               \n",
        "        return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attn_mask,\n",
        "        'label':torch.tensor(self.labels[index],dtype= torch.float)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gma9nMO1reNw"
      },
      "source": [
        "**Fine Tune Bert Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqKqyPAKW3tW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "c707d089-08f2-48a7-a7ff-5b0538a4f147"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-abad7ac7f1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_recipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedRecipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_recipe_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# test loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TaggedRecipes' is not defined"
          ]
        }
      ],
      "source": [
        "# build data loaders\n",
        "# init data class\n",
        "batch_size = 70 # TODO: check\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "# train loader\n",
        "train_recipe_data = TaggedRecipes(x_tr, y_tr, tokenizer=tokenizer)\n",
        "train_loader = DataLoader(train_recipe_data, batch_size, num_workers=12)\n",
        "# test loader\n",
        "test_recipe_data = TaggedRecipes(x_test, y_test, tokenizer=tokenizer)\n",
        "test_loader = DataLoader(test_recipe_data, batch_size, num_workers=12)\n",
        "# validation loader\n",
        "validate_recipe_data = TaggedRecipes(x_val, y_val, tokenizer=tokenizer)\n",
        "validate_loader = DataLoader(validate_recipe_data, batch_size, num_workers=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "be34ad8a3bb2474dafaf3f69d9d0a9cc",
            "06984fcac5844aab950f911ac35e1e99",
            "9aec8d632fa141e3b3f954cd8f0e3222",
            "0b8f33c410404307b46a88ed655d74d1",
            "d13f893541a241a3a93c4269f96dac79",
            "0fadffcbc9734373ad79679dca16c29f",
            "38baaf5ebd2447f585a5f6738e394627",
            "7041db6d6f574ca89075be0f71b2b1df",
            "7a694f7f7f9447a68971aeb7f6a09f73",
            "ab4d22d300aa4fd1b98b12d97a70b3ff",
            "53a58b43ed2e44d497fdfcf61215969a"
          ]
        },
        "id": "n1Q57iXxrkBK",
        "outputId": "6ecd2b10-b473-4c04-d9a1-33951e96987f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 KB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n",
            "Collecting tensorboardX>=2.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0\n",
            "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.25.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Installing collected packages: tensorboardX, torchmetrics, lightning-utilities, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.5.0 pytorch_lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be34ad8a3bb2474dafaf3f69d9d0a9cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# add classification layer\n",
        "# train model on recipe descriptions\n",
        "%pip install torcheval\n",
        "from torcheval.metrics.functional import binary_f1_score\n",
        "\n",
        "# Base bert model: 768 long vectors per token\n",
        "# only 20 tags: add linear layer with 20 ouputs\n",
        "%pip install pytorch_lightning\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-cased\", return_dict=True)\n",
        "\n",
        "# recommended by pytorch: bcewithlogitsloss & sigmoid layer\n",
        "class TagClassifier(pl.LightningModule): # TODO: rewrite as nn.module or include \n",
        "# explaination why LightningModule was used and what it implements for us \n",
        "# https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html\n",
        "  # Setup\n",
        "  def __init__(self,n_classes=len_tags,steps_per_epoch=None,n_epochs=3, lr=2e-5, \n",
        "               optimizer=torch.optim.Adam):\n",
        "    super().__init__()\n",
        "    self.classifier=nn.Linear(bert_model.config.hidden_size,\n",
        "n_classes) \n",
        "    self.steps_per_epoch = steps_per_epoch\n",
        "    self.n_epochs = n_epochs\n",
        "    self.lr = lr\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "    self.optimizer = optimizer\n",
        "    self.model = bert_model\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "    self._name = \"TagClassifier\"\n",
        "    # todo: store this data on checkpoints\n",
        "    self._epoch = 0\n",
        "    self.epoch_losses = [[]] # 2d dict of losses per epoch\n",
        "    self._val_epoch = 0\n",
        "    self.epoch_losses_validation = [[]]\n",
        "    self.f1_scores_validation = [[]]\n",
        "    self.f1_scores = [[]]\n",
        "\n",
        "  def forward(self, input_ids, attn_mask):\n",
        "      # eval bert layers\n",
        "      output_bert = self.model(input_ids=input_ids,attention_mask=attn_mask)\n",
        "      # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "      last_hidden_state_cls = output_bert[0][:, 0, :] # todo: check\n",
        "      # eval calssifier layer on top\n",
        "      output = self.classifier(last_hidden_state_cls)\n",
        "      return output\n",
        "            \n",
        "  def training_step(self, batch, batch_idx):\n",
        "      labels = batch[\"label\"]\n",
        "      input_ids = batch[\"input_ids\"]\n",
        "      attention_mask = batch[\"attention_mask\"]\n",
        "      # forward pass\n",
        "      logits = self(input_ids, attention_mask)\n",
        "      # compute loss\n",
        "      loss = self.loss(logits, labels)\n",
        "      # calc f1 score\n",
        "      f1_score = binary_f1_score(torch.flatten(logits), torch.flatten(labels), threshold = 0.5)\n",
        "      self.log(f\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log(f\"train_f1\", f1_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      # store loss/f1 scores\n",
        "      self.epoch_losses[self._epoch].append(loss)\n",
        "      self.f1_scores[self._epoch].append(f1_score)\n",
        "\n",
        "      tqdm_dict = {f\"train_loss\": loss}\n",
        "      output = dict({\n",
        "          \"loss\": loss,\n",
        "          \"progress_bar\": tqdm_dict,\n",
        "          \"log\": tqdm_dict,\n",
        "          \"f1\" : f1_score\n",
        "          })\n",
        "      return output\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1_score = 0\n",
        "    # avg loss of epoch\n",
        "    for loss in self.epoch_losses[self._epoch]:\n",
        "      epoch_loss += loss\n",
        "    epoch_loss /= len(self.epoch_losses[self._epoch])\n",
        "\n",
        "    # avg f1 score of epoch\n",
        "    for f1_score in self.f1_scores[self._epoch]:\n",
        "      epoch_f1_score += f1_score\n",
        "    epoch_f1_score /= len(self.f1_scores[self._epoch])\n",
        "\n",
        "    # log loss & f1\n",
        "    print(f\"Train Epoch: {self._epoch}, Loss: {epoch_loss.item()}, F1-Score: {epoch_f1_score.item()}\")\n",
        "    self._epoch += 1\n",
        "    self.epoch_losses.append([])\n",
        "    self.f1_scores.append([])\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "      labels = batch[\"label\"]\n",
        "      input_ids = batch[\"input_ids\"]\n",
        "      attention_mask = batch[\"attention_mask\"]\n",
        "      # forward pass\n",
        "      logits = self(input_ids, attention_mask)\n",
        "      # compute loss\n",
        "      loss = self.loss(logits, labels)\n",
        "      # calc f1 score\n",
        "      f1_score = binary_f1_score(torch.flatten(logits), torch.flatten(labels), threshold = 0.5)\n",
        "      # log\n",
        "      self.log(f\"validation_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log(f\"validation_f1\", f1_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      # store loss/f1 scores\n",
        "      self.epoch_losses_validation[self._val_epoch].append(loss)\n",
        "      self.f1_scores_validation[self._val_epoch].append(f1_score)\n",
        "\n",
        "      tqdm_dict = {f\"validation_loss\": loss}\n",
        "      output = dict({\n",
        "          \"loss\": loss,\n",
        "          \"progress_bar\": tqdm_dict,\n",
        "          \"log\": tqdm_dict,\n",
        "          \"f1\" : f1_score\n",
        "          })\n",
        "      return output\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1_score = 0\n",
        "    # avg loss of epoch\n",
        "    for loss in self.epoch_losses_validation[self._val_epoch]:\n",
        "      epoch_loss += loss\n",
        "    epoch_loss /= len(self.epoch_losses_validation[self._val_epoch])\n",
        "\n",
        "    # avg f1 score of epoch\n",
        "    for f1_score in self.f1_scores_validation[self._val_epoch]:\n",
        "      epoch_f1_score += f1_score\n",
        "    # DEBUG - TODO: REMOVE\n",
        "    print(f\"{self._val_epoch=}\")\n",
        "    print(f\"{self.f1_scores=}\")\n",
        "    epoch_f1_score /= len(self.f1_scores_validation[self._val_epoch])\n",
        "\n",
        "    # log loss & f1\n",
        "    print(f\"Validation Epoch: {self._val_epoch}, Loss: {epoch_loss.item()}, F1-Score: {epoch_f1_score.item()}\")\n",
        "    self._val_epoch += 1\n",
        "    self.epoch_losses_validation.append([])\n",
        "    self.f1_scores_validation.append([])\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "        return self.optimizer(self.parameters(), lr=self.lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7t1cV7Q8LV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp4aGCZ3wI_A"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOputRAcwLdT",
        "outputId": "1b0ea4a9-6b69-482e-ffd0-857a41ee4df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# Initialize hyper parameters\n",
        "epochs = 20\n",
        "#batch_size = 1024\n",
        "max_len = 300\n",
        "learning_rate = 2e-05\n",
        "\n",
        "def callback(): # TODO implement\n",
        "  pass\n",
        "\n",
        "# Instantiate the Model Trainer\n",
        "# setup data module (used in fit method of pl)\n",
        "class TagsDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, train_dataloader, test_dataloader, validation_dataloader):\n",
        "    self.train_loader = train_dataloader\n",
        "    self.test_loader = test_dataloader\n",
        "    self.val_loader = validation_dataloader\n",
        "    self.prepare_data_per_node = False # todo: check if can be enabled\n",
        "    self._log_hyperparams = True\n",
        "    self.save_dir = \"/content/drive/MyDrive\"\n",
        "  # methods expected to be implementedd by pl.datamodule\n",
        "  def train_dataloader(self):\n",
        "    return self.train_loader\n",
        "  def test_dataloader(self):\n",
        "    return self.test_loader\n",
        "  def val_dataloader(self):\n",
        "    return self.val_loader\n",
        "\n",
        "tags_data_module = TagsDataModule(train_loader, test_loader, validate_loader)\n",
        "\n",
        "print(len(train_recipe_data))\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = epochs, accelerator = \"gpu\", gpus = [0])#, callbacks=[callback]) # gpus = x, if gpu available\n",
        "model = TagClassifier(len_tags, None, epochs, learning_rate)\n",
        "# Train the Classifier Model\n",
        "#trainer.fit(model, train_dataloaders=tags_data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Khy0_x9LCmOM",
        "outputId": "6053ef1e-b610-4260-dae4-f6e962595251"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# print & plot epoch validation losses\n",
        "def average_loss(tensor_list):\n",
        "  total_loss = 0\n",
        "  for tensor in tensor_list:\n",
        "    total_loss += tensor.item()\n",
        "  return total_loss / len(tensor_list)\n",
        "epoch_losses = [average_loss(x) for x in model.epoch_losses_validation if len(x) > 0]\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "fig = sns.lineplot(data = epoch_losses).set(title=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show(fig)\n",
        "\n",
        "# batch size = 70\n",
        "# -> 50/70 top 20 label predictions completly correct at epoch 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print & plot epoch validation f1-scores\n",
        "epoch_losses = [average_loss(x) for x in model.f1_scores_validation if len(x) > 0]\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "fig = sns.lineplot(data = epoch_losses).set(title=\"Validation f1 score\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "2SMaIkn-ZLmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWMWopcuEu-U"
      },
      "source": [
        "**Create a combined network of the fine tuned bert model and (a fully connnected network) the nutritional values + as additional input. (compare against only nutritional, ingerdients as additional input, ingredients only)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXlhCtFSHv5t"
      },
      "outputs": [],
      "source": [
        "# debugging cell \n",
        "#tagged_data.head(2)\n",
        "batch_size_combined = 60 # TODO: check (~ 1000 should be possible)\n",
        "#model = model.load_from_checkpoint(\"/lightning_logs/version_3/checkpoints/epoch=10-step=5665.ckpt\")\n",
        "#model.eval()\n",
        "# create additional train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBVH19TvFL-J"
      },
      "outputs": [],
      "source": [
        "# fine tuned bert model with classifier\n",
        "bert_label_classifier = model\n",
        "\n",
        "class TagClassifierCombined(pl.LightningModule):\n",
        "  def __init__(self,n_classes=len_tags,steps_per_epoch=None,n_epochs=3, lr=2e-5, \n",
        "               optimizer=torch.optim.Adam):\n",
        "    super().__init__()\n",
        "    # 27 -> output bert classifier = 20, output nutrition network = 7\n",
        "    self.classifier=nn.Linear(27,n_classes) \n",
        "    self.steps_per_epoch = steps_per_epoch\n",
        "    self.n_epochs = n_epochs\n",
        "    self.lr = lr\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "    self.optimizer = optimizer\n",
        "    self.model = bert_label_classifier\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "    self._name = \"CombinedTagClassifier\"\n",
        "    # todo: store this data on checkpoints\n",
        "    self._epoch = 0\n",
        "    self.epoch_losses = [[]] # 2d dict of losses per epoch\n",
        "    self._val_epoch = 0\n",
        "    self.epoch_losses_validation = [[]]\n",
        "    self.f1_scores_validation = [[]]\n",
        "    self.f1_scores = [[]]\n",
        "    # fully connected nutrition layer\n",
        "    self.nutrition_network = nn.Sequential(\n",
        "      nn.Linear(7, batch_size_combined),  # 7 nutrition values per recipe, batch_size = 70 (earlier defined)\n",
        "      nn.ReLU(),  # non linear function between linear layers\n",
        "      nn.Linear(batch_size_combined, 7),\n",
        "      nn.Sigmoid()\n",
        "      #nn.Linear(batch_size_combined, 7),  # one fully connected layer with ReLU activiation function\n",
        "      #nn.ReLU(),  \n",
        "      #nn.Linear(32, batch_size) # TODO: find fitting output size\n",
        "    )\n",
        "\n",
        "  def forward(self, input_ids, attn_mask, nutrition):\n",
        "      # get label prediction from description text (top 20 labels)\n",
        "      output_bert = self.model(input_ids=input_ids,attn_mask=attn_mask)\n",
        "      # output = 20*batch_size x1 tensor\n",
        "      # concat with nutrition network\n",
        "      output_nutrition = self.nutrition_network((nutrition))\n",
        "      # concat 20*batch_size x1 output_bert with 7*batch_size x1 output_nutrition\n",
        "      tensor = torch.cat((output_bert,output_nutrition),1) # creates a 60x27 tensor\n",
        "      # classify\n",
        "      logits = self.classifier(tensor)\n",
        "      return logits\n",
        "\n",
        "  def predict_step(self, batch, batch_idx):\n",
        "      labels = batch[\"label\"]\n",
        "      input_ids = batch[\"input_ids\"]\n",
        "      attention_mask = batch[\"attention_mask\"]\n",
        "      nutrition = batch[\"nutrition\"]\n",
        "      # forward pass\n",
        "      logits = self(input_ids, attention_mask, nutrition)\n",
        "      return logits\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      labels = batch[\"label\"]\n",
        "      input_ids = batch[\"input_ids\"]\n",
        "      attention_mask = batch[\"attention_mask\"]\n",
        "      nutrition = batch[\"nutrition\"]\n",
        "      # forward pass\n",
        "      logits = self(input_ids, attention_mask, nutrition)\n",
        "      # compute loss\n",
        "      loss = self.loss(logits, labels)\n",
        "      # calc f1 score\n",
        "      f1_score = binary_f1_score(torch.flatten(logits), torch.flatten(labels), threshold = 0.5)\n",
        "      self.log(f\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log(f\"train_f1\", f1_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      # store loss/f1 scores\n",
        "      self.epoch_losses[self._epoch].append(loss)\n",
        "      self.f1_scores[self._epoch].append(f1_score)\n",
        "\n",
        "      tqdm_dict = {f\"train_loss\": loss}\n",
        "      output = dict({\n",
        "          \"loss\": loss,\n",
        "          \"progress_bar\": tqdm_dict,\n",
        "          \"log\": tqdm_dict,\n",
        "          \"f1\" : f1_score\n",
        "          })\n",
        "      return output\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1_score = 0\n",
        "\n",
        "    # avg loss of epoch\n",
        "    for loss in self.epoch_losses[self._epoch]:\n",
        "      epoch_loss += loss\n",
        "    epoch_loss /= len(self.epoch_losses[self._epoch])\n",
        "\n",
        "    # avg f1 score of epoch\n",
        "    for f1_score in self.f1_scores[self._epoch]:\n",
        "      epoch_f1_score += f1_score\n",
        "    epoch_f1_score /= len(self.f1_scores[self._epoch])\n",
        "\n",
        "    # log loss & f1\n",
        "    print(f\"Train Epoch: {self._epoch}, Loss: {epoch_loss.item()}, F1-Score: {epoch_f1_score.item()}\")\n",
        "    self._epoch += 1\n",
        "    self.epoch_losses.append([])\n",
        "    self.f1_scores.append([])\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "      labels = batch[\"label\"]\n",
        "      input_ids = batch[\"input_ids\"]\n",
        "      attention_mask = batch[\"attention_mask\"]\n",
        "      nutrition = batch[\"nutrition\"]\n",
        "      # forward pass\n",
        "      logits = self(input_ids, attention_mask, nutrition)\n",
        "      # compute loss\n",
        "      loss = self.loss(logits, labels)\n",
        "      # calc f1 score\n",
        "      f1_score = binary_f1_score(torch.flatten(logits), torch.flatten(labels), threshold = 0.5)\n",
        "      # log\n",
        "      self.log(f\"validation_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log(f\"validation_f1\", f1_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      # store loss/f1 scores\n",
        "      self.epoch_losses_validation[self._val_epoch].append(loss)\n",
        "      self.f1_scores_validation[self._val_epoch].append(f1_score)\n",
        "\n",
        "      tqdm_dict = {f\"validation_loss\": loss}\n",
        "      output = dict({\n",
        "          \"loss\": loss,\n",
        "          \"progress_bar\": tqdm_dict,\n",
        "          \"log\": tqdm_dict,\n",
        "          \"f1\" : f1_score\n",
        "          })\n",
        "      return output\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1_score = 0\n",
        "    # avg loss of epoch\n",
        "    for loss in self.epoch_losses_validation[self._val_epoch]:\n",
        "      epoch_loss += loss\n",
        "    epoch_loss /= len(self.epoch_losses_validation[self._val_epoch])\n",
        "    # avg f1 score of epoch\n",
        "    for f1_score in self.f1_scores_validation[self._val_epoch]:\n",
        "      epoch_f1_score += f1_score\n",
        "    epoch_f1_score /= len(self.f1_scores_validation[self._val_epoch])\n",
        "\n",
        "    # log loss & f1\n",
        "    print(f\"Validation Epoch: {self._val_epoch}, Loss: {epoch_loss.item()}, F1-Score: {epoch_f1_score.item()}\")\n",
        "    self._val_epoch += 1\n",
        "    self.epoch_losses_validation.append([])\n",
        "    self.f1_scores_validation.append([])\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "        return self.optimizer(self.parameters(), lr=self.lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxyVGZOCZfNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99767f9f-2f2a-4116-f5ff-b1055df68696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "class CombinedTaggedRecipes (torch.utils.data.Dataset):\n",
        "    def __init__(self, input, tags, tokenizer):\n",
        "        self.text = input['description'].values.tolist()\n",
        "        self.nutrition = input['nutrition'].values.tolist()\n",
        "        self.labels = tags\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "      text = self.text[index]\n",
        "      inputs = self.tokenizer.encode_plus(\n",
        "          text,\n",
        "          None,\n",
        "          add_special_tokens = True,\n",
        "          max_length = 300,\n",
        "          padding = 'max_length',\n",
        "          return_token_type_ids= False,\n",
        "          return_attention_mask= True,\n",
        "          truncation=True,\n",
        "          return_tensors = 'pt'\n",
        "        )\n",
        "      input_ids = inputs['input_ids'].flatten()\n",
        "      attn_mask = inputs['attention_mask'].flatten()             \n",
        "      return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attn_mask,\n",
        "        'nutrition': torch.tensor(self.nutrition[index], dtype=torch.float),\n",
        "        'label':torch.tensor(self.labels[index], dtype=torch.float)\n",
        "      }\n",
        "\n",
        "# build data loaders\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "# train loader\n",
        "train_recipe_data_combined = CombinedTaggedRecipes(x_tr, y_train, tokenizer)\n",
        "train_loader_combined = DataLoader(train_recipe_data_combined, batch_size_combined, num_workers=12)\n",
        "# test loader\n",
        "test_recipe_data_combined = CombinedTaggedRecipes(x_test, y_test, tokenizer)\n",
        "test_loader_combined = DataLoader(test_recipe_data_combined, batch_size_combined, num_workers=12)\n",
        "# validation loader\n",
        "validate_recipe_data_combined = CombinedTaggedRecipes(x_val, y_val, tokenizer)\n",
        "validate_loader_combined = DataLoader(validate_recipe_data_combined, batch_size_combined, num_workers=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vl4vKd3h_5Z"
      },
      "source": [
        "**Train the combined model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "26a19baf287040a1868d944e757c2cd6",
            "48e0e74616014e1e87c0d205aeb933c5",
            "24caabec4e624b04a93bc984945efffa",
            "d01aa522966643d4a0b7cf867167a88c",
            "b81d4dd85402471ab5b7cdcf0533faf6",
            "d8289f5617c74a34997b85788c149fe2",
            "9a01ff8d17594dac934b880712c4c240",
            "e74ca252815d4b49bc2ffd069e144cef",
            "e428cadbd6ab433199895e7e4ed06e70",
            "0e2f232d7c5842d3a45db83f0c6bc440",
            "0cd0ebf742ba4540a18a7f1e38b69d4c",
            "63a7da8f3c2c4c96989073084fd400ca",
            "dae486fa81464e33b43f6ae965bfb258",
            "74955ed631504d39a37b1bba2f980e44",
            "e7d4f2bd68644f23947d5c41734aa584",
            "af62df57bfdd403e98601de97e68b2c9",
            "2534d67632204e98bc326c6434a19d88",
            "5bf7d29755f34ac49663164c34ef7f2b",
            "361083fa1b3f4def9379e5d1cf479ac4",
            "65fbdd3ddfb84bed92c6e4660acd75bd",
            "57fb048f27f5414b81355068a6b90348",
            "0f77db47c1e24211b3da5c3cd79b1fc2"
          ]
        },
        "id": "yGPbWs0xiCUd",
        "outputId": "180edd1c-2559-4117-fa67-4d46b1393565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type              | Params\n",
            "--------------------------------------------------------\n",
            "0 | classifier        | Linear            | 560   \n",
            "1 | criterion         | BCEWithLogitsLoss | 0     \n",
            "2 | model             | TagClassifier     | 108 M \n",
            "3 | loss              | CrossEntropyLoss  | 0     \n",
            "4 | nutrition_network | Sequential        | 907   \n",
            "--------------------------------------------------------\n",
            "108 M     Trainable params\n",
            "0         Non-trainable params\n",
            "108 M     Total params\n",
            "433.308   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a19baf287040a1868d944e757c2cd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch: 0, Loss: 235.64675903320312\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63a7da8f3c2c4c96989073084fd400ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-961c954289f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagClassifierCombined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train the Classifier Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_data_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`Trainer.fit()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         )\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             )\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# the `batch_idx` is optional with inter-batch parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         self.trainer._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# TODO(lite): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         return self.precision_plugin.optimizer_step(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_track_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mconsistent\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msubclasses\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# manually capture logged metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-364643b2c99c>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mnutrition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nutrition\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnutrition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-364643b2c99c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attn_mask, nutrition)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnutrition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# get label prediction from description text (top 20 labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0moutput_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0;31m# output = 20*batch_size x1 tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;31m# concat with nutrition network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-c59836372434>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attn_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;31m# eval bert layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0moutput_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0;31m# Extract the last hidden state of the token `[CLS]` for classification task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mlast_hidden_state_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_bert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# todo: check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         )\n\u001b[0;32m-> 1021\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 426\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 248.00 MiB (GPU 0; 14.76 GiB total capacity; 13.33 GiB already allocated; 155.75 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Initialize hyper parameters\n",
        "epochs = 20\n",
        "#batch_size = 1024\n",
        "learning_rate = 2e-05\n",
        "\n",
        "def callback(): # TODO implement\n",
        "  pass\n",
        "\n",
        "# Instantiate the Model Trainer\n",
        "combined_data_module = TagsDataModule(train_loader_combined, test_loader_combined, validate_loader_combined)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = epochs, accelerator = \"gpu\", gpus = [0])#, callbacks=[callback]) # gpus = x, if gpu available\n",
        "model_combined = TagClassifierCombined(len_tags, None, epochs, learning_rate)\n",
        "# Train the Classifier Model\n",
        "trainer.fit(model_combined, train_dataloaders=combined_data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot of the loss per epoch**"
      ],
      "metadata": {
        "id": "_Wb7cxVJAbjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_losses = [average_loss(x) for x in model_combined.epoch_losses_validation if len(x) > 0]\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "fig = sns.lineplot(data = epoch_losses).set(title=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "GhDXOKA0AgIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEouZ3hRfnmR"
      },
      "outputs": [],
      "source": [
        "# for later comparison: recommendation based on cosine-similarity of nutrition\n",
        "def similar_recipes_nutrition(recipe_id):\n",
        "  recipe_nutrition = data.loc[data['id'] == recipe_id]['nutrition'].values[0]\n",
        "  # TODO: filter out same recipe id\n",
        "  cosine_sim = [(row, np.dot(recipe_nutrition, nutrition) / (norm(recipe_nutrition)*norm(nutrition))) for row, nutrition in (zip(data['id'], data['nutrition']))]\n",
        "  ordered_cosine_similarites = sorted(cosine_sim, reverse=True, key=lambda d: d[1])\n",
        "  return ordered_cosine_similarites\n",
        "\n",
        "similar = similar_recipes_nutrition(31490) # a different breakfast pizza\n",
        "print(similar[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8N3ZPJlhmYO"
      },
      "source": [
        "**Train a model with input data = user_id, nutrition, rating and compare the recommendations (precision, recall) to pure nutrition similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mDIfMu3KkMk"
      },
      "outputs": [],
      "source": [
        "# Plot number of ratings per user\n",
        "#rating_data.groupby(['user_id']).size().plot(kind = \"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BXm_PZfhjl6"
      },
      "outputs": [],
      "source": [
        "# split into training and test data, make sure that for each user 70% = train, 30% = test to represent each user.\n",
        "rating_data = pd.merge(raw_recipes, raw_interactions, left_on='id', right_on='recipe_id')\n",
        "train_split = 0.7\n",
        "\n",
        "train_data = []\n",
        "test_data  = []\n",
        "users_min = 0\n",
        "\n",
        "min_ratings = 6\n",
        "# TODO: add max ratings per user?\n",
        "grouped = rating_data.groupby('user_id')\n",
        "for name, group in grouped:\n",
        "    #print('ID: ' + str(name))\n",
        "    ratings_by_user = group.shape[0]\n",
        "    # skip users with < min_ratings\n",
        "    if ratings_by_user < min_ratings:\n",
        "      continue\n",
        "    users_min +=1\n",
        "    train_ratings = math.floor(train_split * ratings_by_user)\n",
        "    test_ratings = ratings_by_user - train_ratings\n",
        "    train = group.head(train_ratings)[['user_id', 'nutrition', 'rating']].values.tolist()\n",
        "    test = group.tail(test_ratings)[['user_id', 'nutrition', 'rating']].values.tolist()\n",
        "    train_data.extend(train)\n",
        "    test_data.extend(test)\n",
        "\n",
        "print(len(test_data))\n",
        "print(len(train_data))\n",
        "print(users_min)\n",
        "# TODO: model user based on nutrition priorities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daRTUvpv8dVx"
      },
      "source": [
        "# 1.1): Generate ingredient and recipe embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Create a dict of all words (each useed ingredient) and one-hot-encodings**"
      ],
      "metadata": {
        "id": "9v-zPVSCsE_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags_diet = ['low-sodium', 'low-carb', 'healthy', 'low-cholesterol', 'low-calorie']\n",
        "tags_occasion = ['dinner-party', 'holiday-event', 'lunch', 'weeknight', 'brunch']\n",
        "tags_time = ['60-minutes-or-less',\n",
        "             '30-minutes-or-less',\n",
        "             '4-hours-or-less',\n",
        "             '3-steps-or-less',\n",
        "             '15-minutes-or-less']\n",
        "tags_country = ['north-american', 'american', 'european', 'asian', 'italian']\n",
        "tags_dish_kind = ['desserts', 'pasta-rice-and-grains', 'side-dishes', 'appetizers',\n",
        "                  'pasta', 'cookies-and-brownies', 'soups-stews', 'beverages', 'cakes']\n",
        "\n",
        "data = data.assign(tags_diet =       lambda x: [[words_row.count(word) for word in tags_diet] for words_row in x['tags']], axis=1)\n",
        "data['tags_diet'] = data['tags_diet'].apply(lambda x: np.array(x, dtype='f'))\n",
        "data = data.assign(tags_occasion =   lambda x: [[words_row.count(word) for word in tags_occasion] for words_row in x['tags']], axis=1)       \n",
        "data['tags_occasion'] = data['tags_occasion'].apply(lambda x: np.array(x, dtype='f'))\n",
        "data = data.assign(tags_time =       lambda x: [[words_row.count(word) for word in tags_time] for words_row in x['tags']], axis=1)       \n",
        "data['tags_time'] = data['tags_time'].apply(lambda x: np.array(x, dtype='f'))\n",
        "data = data.assign(tags_country =    lambda x: [[words_row.count(word) for word in tags_country] for words_row in x['tags']], axis=1)       \n",
        "data['tags_country'] = data['tags_country'].apply(lambda x: np.array(x, dtype='f'))\n",
        "data = data.assign(tags_dish_kind =  lambda x: [[words_row.count(word) for word in tags_dish_kind] for words_row in x['tags']], axis=1)\n",
        "data['tags_dish_kind'] = data['tags_dish_kind'].apply(lambda x: np.array(x, dtype='f'))\n"
      ],
      "metadata": {
        "id": "PWel56ERPt94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "data[['tags_diet']].values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Bgbw1utWJk",
        "outputId": "8db1f1fc-0b44-4330-92c0-ed9be000ca3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([0, 0, 0, 0, 0])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Create groups of tags for later multi target learning**"
      ],
      "metadata": {
        "id": "S1PBGSBWPlvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict of all unique ingredients\n",
        "dictionary = dict()\n",
        "\n",
        "# create lookup dict\n",
        "i = 0\n",
        "for ingredientlist in data['ingredients']:\n",
        "  for ingredient in ingredientlist:\n",
        "    if ingredient not in dictionary:\n",
        "      dictionary[ingredient] = 1\n",
        "    else:\n",
        "      dictionary[ingredient] += 1"
      ],
      "metadata": {
        "id": "1tyNuMbtXkPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordered_ingredients = dict(sorted(dictionary.items(), reverse=True, key=lambda d: d[1])[:200])\n",
        "print(ordered_ingredients)\n",
        "keys = list(ordered_ingredients.keys())[:20]\n",
        "vals = list(ordered_ingredients.values())[:20]\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.xlabel(\"Ingredient\")\n",
        "plt.ylabel(\"Amount\")\n",
        "plt.bar(keys, vals)\n",
        "\n",
        "keys = list(ordered_ingredients.keys())\n",
        "vals = list(ordered_ingredients.values())\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.xlabel(\"Ingredient\")\n",
        "plt.ylabel(\"Amount\")\n",
        "plt.xticks([])\n",
        "plt.bar(keys, vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "uWjftHX8Xt_S",
        "outputId": "92abd6d8-e1c1-4f43-bf95-6e9cfff91db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'salt': 85746, 'butter': 54975, 'sugar': 44535, 'onion': 39065, 'water': 34914, 'eggs': 33761, 'olive oil': 32822, 'flour': 26266, 'milk': 25786, 'garlic cloves': 25748, 'pepper': 22319, 'brown sugar': 18655, 'garlic': 18087, 'all-purpose flour': 17659, 'baking powder': 17504, 'egg': 17304, 'salt and pepper': 15415, 'parmesan cheese': 14807, 'lemon juice': 14233, 'baking soda': 14099, 'vegetable oil': 13912, 'vanilla': 13315, 'black pepper': 13098, 'cinnamon': 12560, 'tomatoes': 11950, 'sour cream': 11779, 'garlic powder': 10887, 'vanilla extract': 10271, 'oil': 9925, 'honey': 9898, 'onions': 9872, 'cream cheese': 9827, 'garlic clove': 9779, 'celery': 9541, 'cheddar cheese': 8969, 'unsalted butter': 8935, 'soy sauce': 8856, 'mayonnaise': 8736, 'paprika': 7982, 'chicken broth': 7963, 'worcestershire sauce': 7832, 'extra virgin olive oil': 7704, 'fresh parsley': 7656, 'cornstarch': 7486, 'fresh ground black pepper': 7160, 'carrots': 7023, 'parsley': 7001, 'chili powder': 6984, 'bacon': 6948, 'ground cinnamon': 6864, 'carrot': 6707, 'potatoes': 6507, 'nutmeg': 6299, 'cayenne pepper': 6285, 'granulated sugar': 6254, 'ground cumin': 6169, 'ground beef': 5824, 'green onions': 5814, 'red onion': 5777, 'walnuts': 5765, 'pecans': 5752, 'dijon mustard': 5599, 'green onion': 5585, 'kosher salt': 5583, 'powdered sugar': 5377, 'fresh lemon juice': 5311, 'heavy cream': 5201, 'margarine': 5077, 'mozzarella cheese': 4980, 'dried oregano': 4882, 'orange juice': 4702, 'zucchini': 4591, 'raisins': 4487, 'red bell pepper': 4450, 'tomato sauce': 4402, 'fresh cilantro': 4360, 'chicken stock': 4352, 'tomato paste': 4335, 'canola oil': 4315, 'green pepper': 4301, 'fresh ginger': 4255, 'cumin': 4233, 'oregano': 4185, 'boneless skinless chicken breasts': 3994, 'ground black pepper': 3936, 'ketchup': 3901, 'balsamic vinegar': 3848, 'buttermilk': 3825, 'lime juice': 3749, 'cilantro': 3742, 'ground ginger': 3655, 'fresh basil': 3636, 'ginger': 3600, 'onion powder': 3598, 'dried thyme': 3533, 'diced tomatoes': 3462, 'vinegar': 3395, 'green bell pepper': 3287, 'egg whites': 3258, 'dried basil': 3253, 'bay leaf': 3253, 'white sugar': 3228, 'red wine vinegar': 3223, 'fresh ground pepper': 3220, 'whipping cream': 3158, \"confectioners' sugar\": 3140, 'sea salt': 3138, 'dry white wine': 3130, 'salt & freshly ground black pepper': 3123, 'whole wheat flour': 3053, 'light brown sugar': 3026, 'sesame oil': 2988, 'thyme': 2980, 'curry powder': 2959, 'crushed red pepper flakes': 2936, 'ground nutmeg': 2925, 'lemon': 2901, 'white wine': 2890, 'dry mustard': 2839, 'white pepper': 2837, 'chicken breasts': 2793, 'breadcrumbs': 2773, 'bananas': 2747, 'shortening': 2744, 'boiling water': 2733, 'basil': 2727, 'mushrooms': 2718, 'cheese': 2712, 'salsa': 2703, 'garlic salt': 2636, 'egg yolks': 2623, 'semi-sweet chocolate chips': 2606, 'red pepper flakes': 2602, 'lean ground beef': 2560, 'cider vinegar': 2540, 'bay leaves': 2537, 'feta cheese': 2510, 'sharp cheddar cheese': 2483, 'black beans': 2468, 'scallions': 2425, 'nuts': 2421, 'monterey jack cheese': 2411, 'peanut butter': 2363, 'fresh lime juice': 2353, 'banana': 2327, 'ground cloves': 2321, 'yellow onion': 2297, 'half-and-half': 2265, 'seasoning salt': 2261, 'red pepper': 2252, 'chocolate chips': 2232, 'shallots': 2197, 'apples': 2193, 'tabasco sauce': 2188, 'white vinegar': 2184, 'fresh thyme': 2184, 'cucumber': 2176, 'salt & pepper': 2156, 'cream of mushroom soup': 2138, 'cold water': 2138, 'sesame seeds': 2134, 'evaporated milk': 2129, 'skim milk': 2125, 'hot sauce': 2124, 'chicken': 2115, 'cream': 2100, 'cooking spray': 2091, 'beef broth': 2090, 'fresh mushrooms': 2079, 'shallot': 2066, 'lemon, juice of': 2056, 'warm water': 2054, 'almond extract': 2046, 'swiss cheese': 2043, 'ground coriander': 2041, 'mushroom': 2020, 'lemon zest': 1993, 'italian seasoning': 1990, 'black olives': 1981, 'maple syrup': 1962, 'cooked chicken': 1931, 'whole milk': 1931, 'celery ribs': 1919, 'bread': 1903, 'shrimp': 1903, 'sliced mushrooms': 1899, 'avocado': 1894, 'turmeric': 1858, 'cayenne': 1855, 'cabbage': 1844, 'plain yogurt': 1818, 'sweetened condensed milk': 1811, 'green chilies': 1810, 'fresh rosemary': 1807, 'hot water': 1795, 'cocoa': 1791, 'chives': 1757, 'boneless skinless chicken breast halves': 1753, 'molasses': 1740, 'dark brown sugar': 1735}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 200 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create column with filtered ingredients (in top 200)\n",
        "def ingredientFilter(ingredients):\n",
        "  table = []\n",
        "  for row in ingredients:\n",
        "    data = [ingredient for ingredient in row if ingredient in ordered_ingredients]\n",
        "    table.append(data)\n",
        "  return table\n",
        "\n",
        "def ingredientCount(ingredients):\n",
        "  table = []\n",
        "  for row in ingredients:\n",
        "    table.append(len(row))\n",
        "  return table\n",
        "\n",
        "data = data.assign(filtered_ingredients = lambda row: ingredientFilter(row['ingredients']), axis=1)\n",
        "data = data.assign(num_ingredients = lambda row: ingredientCount(row['filtered_ingredients']), axis=1)\n",
        "# filter recipes with less than 5 ingredients\n",
        "min_ingredients = 5\n",
        "filtered_recipes = data[data['num_ingredients'] > min_ingredients]"
      ],
      "metadata": {
        "id": "FLcQkmuoc7X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_recipes) # 198k\n",
        "filtered_recipes['num_ingredients'].head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w89PY-TDdW1e",
        "outputId": "a2ace4db-d5da-4f93-c83d-9ea0db2f12c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2      8\n",
              "3      7\n",
              "7     12\n",
              "9      7\n",
              "12    10\n",
              "19     8\n",
              "21     7\n",
              "22     9\n",
              "23    13\n",
              "26     9\n",
              "27     7\n",
              "29    13\n",
              "30     7\n",
              "31     7\n",
              "33     6\n",
              "41    16\n",
              "42    12\n",
              "44    10\n",
              "47     9\n",
              "48     7\n",
              "49     7\n",
              "50    15\n",
              "51     9\n",
              "55     8\n",
              "56     7\n",
              "57    13\n",
              "59     6\n",
              "62     7\n",
              "64     9\n",
              "66     7\n",
              "Name: num_ingredients, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHFXGGmv8aVa"
      },
      "outputs": [],
      "source": [
        "# dict of all unique ingredients\n",
        "dictionary = dict()\n",
        "# create lookup dict\n",
        "i = 0\n",
        "for ingredientlist in filtered_recipes['filtered_ingredients']:\n",
        "  for ingredient in ingredientlist:\n",
        "    if ingredient not in dictionary:\n",
        "      dictionary[ingredient] = i\n",
        "      i += 1\n",
        "\n",
        "# create a one-hot-encoded vector for each word (ingredient)\n",
        "one_hot_encodings = dict()\n",
        "total_words = len(dictionary)\n",
        "for word, index in dictionary.items():\n",
        "  word_vec = [0 for i in range(total_words)]\n",
        "  word_vec[index] = 1\n",
        "  one_hot_encodings[index] = np.array(word_vec)\n",
        "\n",
        "# prepare data with sliding window size = 5 (todo: check vs 10)\n",
        "def prepare_data(corpus, n_gram = 2):\n",
        "  token_targets = []\n",
        "  for index, sentence in enumerate(corpus):\n",
        "    row = filtered_recipes.iloc[index]\n",
        "    diet = row['tags_diet']\n",
        "    occasion = row['tags_occasion']\n",
        "    country = row['tags_country']\n",
        "    time = row['tags_time']\n",
        "    dish = row['tags_dish_kind']\n",
        "    for i in range(len(sentence)): # for each word\n",
        "      # sliding window\n",
        "      for w in range(-n_gram,n_gram+1):\n",
        "          if i+w < 0 or i+w >= len(sentence): # border check\n",
        "              continue\n",
        "          if w == 0: # ignore self\n",
        "              continue\n",
        "          # convert to position in dict\n",
        "          target_pos = dictionary[sentence[i]]\n",
        "          neighbor_pos = dictionary[sentence[i+w]]\n",
        "          # convert to one-hot encoding\n",
        "          target_hot = one_hot_encodings[target_pos]\n",
        "          neighbor_hot = one_hot_encodings[neighbor_pos]\n",
        "          token_targets.append((target_hot, neighbor_hot, diet, occasion, country, time, dish))\n",
        "  return token_targets\n",
        "\n",
        "token_targets = prepare_data(filtered_recipes['filtered_ingredients'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: CHECK batch size (might run out of gpu mem)\n",
        "BATCH_SIZE = 15\n",
        "\n",
        "# split into train/test sets\n",
        "test_size = .1\n",
        "x_train,x_test,_,_ = train_test_split(token_targets, token_targets, test_size=test_size, random_state=SEED,shuffle=True)\n",
        "\n",
        "# sanity check\n",
        "print(x_train[0])\n",
        "\n",
        "print(f\"{len(x_train)=}\")\n",
        "print(f\"{len(x_test)=}\")\n",
        "\n",
        "# lack of training time - reduce data size by factor 25\n",
        "x_train = x_train[:math.floor(len(x_train) / 100)]\n",
        "x_test = x_test[:math.floor(len(x_test) / 100)]\n",
        "\n",
        "# make data a multiple of batch size\n",
        "x_allign_train = len(x_train) - (len(x_train) % BATCH_SIZE)\n",
        "x_allign_test  = len(x_test) -  (len(x_test) % BATCH_SIZE)\n",
        "\n",
        "x_train = x_train[:x_allign_train]\n",
        "x_test = x_test[:x_allign_test]\n",
        "\n",
        "# sanity check\n",
        "print(f\"{len(x_train)=}\")\n",
        "print(f\"{len(x_test)=}\")\n",
        "\n",
        "# DEBUG _ TODO REMOVE\n",
        "#x_train = x_train[:5]\n",
        "#x_test = x_test[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKUKBzjjlf--",
        "outputId": "ac9eaf84-66a0-4ba9-a26c-8d81d53a263b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0]), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 1., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\n",
            "len(x_train)=2815095\n",
            "len(x_test)=312789\n",
            "len(x_train)=28140\n",
            "len(x_test)=3120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data loader\n",
        "# TODO REMOVE :15\n",
        "train_dataloader= DataLoader(x_train, batch_size = BATCH_SIZE)\n",
        "test_dataloader = DataLoader(x_test, batch_size = BATCH_SIZE)\n",
        "\n",
        "# (01000000000000000, 0000000000100000000000, labelA, labelB, labelC, labelD)"
      ],
      "metadata": {
        "id": "KpBKndBhAzT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "print(len(dictionary))\n",
        "print(dictionary)\n",
        "for x in train_dataloader:\n",
        "    print(x[0].shape)\n",
        "    print(x[1].shape)\n",
        "    print(x[2].shape)\n",
        "    print(x[3].shape)\n",
        "    print(x[4].shape)\n",
        "    print(x[5].shape)\n",
        "    print(x[6].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj6G8i1hYbT0",
        "outputId": "b434b6a3-c6e0-46c3-814b-4685f47d887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{'ground beef': 0, 'diced tomatoes': 1, 'tomato paste': 2, 'water': 3, 'chili powder': 4, 'ground cumin': 5, 'salt': 6, 'cheddar cheese': 7, 'shallots': 8, 'parsley': 9, 'olive oil': 10, 'red wine vinegar': 11, 'pepper': 12, 'red bell pepper': 13, 'soy sauce': 14, 'fresh ginger': 15, 'tomato sauce': 16, 'brown sugar': 17, 'yellow onion': 18, 'white vinegar': 19, 'honey': 20, 'cumin': 21, 'dry mustard': 22, 'sugar': 23, 'unsalted butter': 24, 'bananas': 25, 'eggs': 26, 'fresh lemon juice': 27, 'baking soda': 28, 'dark brown sugar': 29, 'molasses': 30, 'cornstarch': 31, 'onion': 32, 'garlic powder': 33, 'black pepper': 34, 'bacon': 35, 'canola oil': 36, 'garlic': 37, 'potatoes': 38, 'ground coriander': 39, 'salt and pepper': 40, 'fresh parsley': 41, 'celery': 42, 'dried thyme': 43, 'white pepper': 44, 'boneless skinless chicken breast halves': 45, 'egg': 46, 'seasoning salt': 47, 'all-purpose flour': 48, 'paprika': 49, 'oil': 50, 'granulated sugar': 51, 'baking powder': 52, 'vanilla extract': 53, 'milk': 54, 'vegetable oil': 55, 'bread': 56, 'ground cinnamon': 57, 'butter': 58, 'powdered sugar': 59, 'green pepper': 60, 'red pepper flakes': 61, 'tomatoes': 62, 'zucchini': 63, 'cabbage': 64, 'parmesan cheese': 65, 'carrot': 66, 'dried oregano': 67, 'dry white wine': 68, 'chicken stock': 69, 'worcestershire sauce': 70, 'tabasco sauce': 71, 'black beans': 72, 'heavy cream': 73, 'vanilla': 74, 'ground cloves': 75, 'orange juice': 76, 'flour': 77, 'cinnamon': 78, 'pecans': 79, 'raisins': 80, 'boiling water': 81, 'green onion': 82, 'chives': 83, 'cheese': 84, 'cider vinegar': 85, 'onion powder': 86, 'italian seasoning': 87, 'shortening': 88, 'nutmeg': 89, 'sharp cheddar cheese': 90, 'nuts': 91, 'dried basil': 92, 'ground black pepper': 93, 'mozzarella cheese': 94, 'ketchup': 95, 'hot sauce': 96, 'sour cream': 97, 'salsa': 98, 'chicken breasts': 99, 'fresh ground black pepper': 100, 'cream': 101, 'lemon juice': 102, 'basil': 103, 'carrots': 104, 'onions': 105, 'bay leaf': 106, 'thyme': 107, 'fresh basil': 108, 'sliced mushrooms': 109, 'oregano': 110, 'cayenne pepper': 111, 'monterey jack cheese': 112, 'sesame oil': 113, 'green onions': 114, 'cooked chicken': 115, 'fresh cilantro': 116, 'sesame seeds': 117, 'cayenne': 118, 'fresh ground pepper': 119, 'scallions': 120, 'lean ground beef': 121, 'cucumber': 122, 'cocoa': 123, 'hot water': 124, 'breadcrumbs': 125, 'ginger': 126, 'white sugar': 127, 'walnuts': 128, 'chocolate chips': 129, 'cream cheese': 130, 'sweetened condensed milk': 131, 'whole wheat flour': 132, 'buttermilk': 133, 'mushrooms': 134, 'extra virgin olive oil': 135, 'vinegar': 136, 'lemon, juice of': 137, 'beef broth': 138, 'kosher salt': 139, 'swiss cheese': 140, 'garlic cloves': 141, 'margarine': 142, 'bay leaves': 143, 'whole milk': 144, 'almond extract': 145, 'chicken': 146, 'mayonnaise': 147, 'ground ginger': 148, 'semi-sweet chocolate chips': 149, 'light brown sugar': 150, 'warm water': 151, 'lemon zest': 152, 'apples': 153, 'balsamic vinegar': 154, 'fresh mushrooms': 155, 'chicken broth': 156, 'maple syrup': 157, 'green bell pepper': 158, 'red onion': 159, 'sea salt': 160, 'garlic clove': 161, 'shallot': 162, 'boneless skinless chicken breasts': 163, 'turmeric': 164, 'salt & freshly ground black pepper': 165, 'black olives': 166, 'cilantro': 167, 'fresh lime juice': 168, 'dijon mustard': 169, 'feta cheese': 170, 'lime juice': 171, 'cream of mushroom soup': 172, 'lemon': 173, 'garlic salt': 174, 'avocado': 175, 'celery ribs': 176, 'egg yolks': 177, 'whipping cream': 178, 'skim milk': 179, 'cooking spray': 180, 'cold water': 181, 'curry powder': 182, 'half-and-half': 183, 'red pepper': 184, 'egg whites': 185, 'banana': 186, 'ground nutmeg': 187, 'fresh thyme': 188, 'white wine': 189, 'crushed red pepper flakes': 190, 'mushroom': 191, 'plain yogurt': 192, \"confectioners' sugar\": 193, 'green chilies': 194, 'fresh rosemary': 195, 'evaporated milk': 196, 'peanut butter': 197, 'salt & pepper': 198, 'shrimp': 199}\n",
            "torch.Size([15, 200])\n",
            "torch.Size([15, 200])\n",
            "torch.Size([15, 5])\n",
            "torch.Size([15, 5])\n",
            "torch.Size([15, 5])\n",
            "torch.Size([15, 5])\n",
            "torch.Size([15, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIMENSION = 16 # TODO: check\n",
        "EMBED_MAX_NORM = 1\n",
        "device = \"cuda\"\n",
        "\n",
        "# encode / decode layer params\n",
        "hidden_dimensions = 512\n",
        "num_heads = 8\n",
        "total_layers = 6 # TODO: check\n",
        "\n",
        "label_types_a = 5 #  diet\n",
        "label_types_b = 5 #  occasion\n",
        "label_types_c = 5 #  time\n",
        "label_types_d = 5 #  country\n",
        "label_types_e = 9 #  cuisine\n",
        "\n",
        "# init model\n",
        "# as described in air hw2 \n",
        "class SkipGramModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of Skip-Gram model described in paper:\n",
        "    https://arxiv.org/abs/1301.3781\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int):\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=EMBED_DIMENSION,\n",
        "            #max_norm=EMBED_MAX_NORM,\n",
        "        )\n",
        "        self.linear = nn.Linear(\n",
        "            in_features=EMBED_DIMENSION,\n",
        "            out_features=vocab_size,\n",
        "        )\n",
        "        # encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=EMBED_DIMENSION, nhead=8)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
        "        # decoder\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=EMBED_DIMENSION, nhead=8)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=4)\n",
        "        # multiple fully conected layers\n",
        "        # (1x2400 and 12000x5)\n",
        "        self.fully_connected_labeltypeA = nn.Sequential(\n",
        "          nn.Linear(3*1000*EMBED_DIMENSION, label_types_a * BATCH_SIZE * 10),  \n",
        "          nn.ReLU(),\n",
        "          nn.Linear(label_types_a * BATCH_SIZE * 10, EMBED_DIMENSION * 10),\n",
        "          nn.ReLU(),  \n",
        "          nn.Linear(EMBED_DIMENSION * 10, label_types_a * BATCH_SIZE),\n",
        "          nn.Sigmoid()# TODO: check\n",
        "        )\n",
        "        self.fully_connected_labeltypeB = nn.Sequential(\n",
        "          nn.Linear(3*1000*EMBED_DIMENSION, label_types_b * BATCH_SIZE * 10),  \n",
        "          nn.ReLU(), \n",
        "          nn.Linear(label_types_b * BATCH_SIZE * 10, EMBED_DIMENSION * 10),\n",
        "          nn.ReLU(),  \n",
        "          nn.Linear(EMBED_DIMENSION * 10, label_types_b * BATCH_SIZE),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "        self.fully_connected_labeltypeC = nn.Sequential(\n",
        "          nn.Linear(3*1000*EMBED_DIMENSION, label_types_c * BATCH_SIZE * 10),  \n",
        "          nn.ReLU(), \n",
        "          nn.Linear(label_types_c * BATCH_SIZE * 10, EMBED_DIMENSION * 10),\n",
        "          nn.ReLU(),  \n",
        "          nn.Linear(EMBED_DIMENSION * 10, label_types_c * BATCH_SIZE),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "        self.fully_connected_labeltypeD = nn.Sequential(\n",
        "          nn.Linear(3*1000*EMBED_DIMENSION, label_types_d *BATCH_SIZE * 10),  \n",
        "          nn.ReLU(), \n",
        "          nn.Linear(label_types_d * BATCH_SIZE * 10, EMBED_DIMENSION * 10),\n",
        "          nn.ReLU(),  \n",
        "          nn.Linear(EMBED_DIMENSION * 10, label_types_d * BATCH_SIZE),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "        # self.fully_connected_labeltypeE = nn.Sequential(\n",
        "        #   nn.Linear(3*1000*EMBED_DIMENSION, label_types_e * BATCH_SIZE),  \n",
        "        #   nn.ReLU(), \n",
        "        #   nn.Linear(label_types_e * BATCH_SIZE, EMBED_DIMENSION),\n",
        "        #   nn.ReLU(),  \n",
        "        #   nn.Linear(EMBED_DIMENSION, label_types_e * BATCH_SIZE),\n",
        "        #   #nn.Sigmoid()\n",
        "        # )\n",
        "        self.train_losses = []\n",
        "        self.test_losses = []\n",
        "    def forward(self, src, target):\n",
        "        # embedding layer\n",
        "        src = self.embeddings(src)\n",
        "        #target = src\n",
        "        target = self.embeddings(target)\n",
        "        # transformer (with attention layers)\n",
        "        memory = self.encoder(src)\n",
        "        transformer_out = self.decoder(target, memory) # 32 vs 14942\n",
        "        # flatten & feed to fully connected layer\n",
        "        transformer_out = torch.flatten(transformer_out)\n",
        "        # multi target learning - multiple fully connected layers \n",
        "        label_a = self.fully_connected_labeltypeA(transformer_out)\n",
        "        label_b = self.fully_connected_labeltypeB(transformer_out) \n",
        "        label_c = self.fully_connected_labeltypeC(transformer_out)\n",
        "        label_d = self.fully_connected_labeltypeD(transformer_out)\n",
        "        #label_e = self.fully_connected_labeltypeE(transformer_out)\n",
        "        #\n",
        "        label_a = label_a.reshape((BATCH_SIZE,5))\n",
        "        label_b = label_b.reshape((BATCH_SIZE,5))\n",
        "        label_c = label_c.reshape((BATCH_SIZE,5))\n",
        "        label_d = label_d.reshape((BATCH_SIZE,5))\n",
        "        #label_e = label_e.reshape((BATCH_SIZE,9))\n",
        "        # todo: stack label_a, b, c, d, e in a single tensor?\n",
        "        return [label_a, label_b, label_c, label_d] #label_e]\n",
        "\n",
        "    \n",
        "vocab_size = total_words\n",
        "skipgram_model = SkipGramModel(vocab_size).to(device)\n",
        "#skipgram_model.double()"
      ],
      "metadata": {
        "id": "3lcDsRq16nj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "%pip install torcheval\n",
        "from torcheval.metrics.functional import binary_f1_score\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    loss = 0\n",
        "    count = 0\n",
        "    f1 = 0\n",
        "    for batch, data in enumerate(dataloader): # for batch in dataloader\n",
        "      tokens = data[0]\n",
        "      targets = data[1]\n",
        "      label_a = (data[2].to(device))\n",
        "      label_b = (data[3].to(device))\n",
        "      label_c = (data[4].to(device))\n",
        "      label_d = (data[5].to(device))\n",
        "      #label_e = (data[6].to(device))\n",
        "      #print(label_a)\n",
        "      _predict_a, _predict_b, _predict_c, _predict_d = model(tokens.to(device), targets.to(device))\n",
        "      # -> calc loss of all targets\n",
        "      #print(f\"{_predict_a.shape=}, {label_a.shape=}\")\n",
        "      loss_a = loss_fn(_predict_a, label_a) \n",
        "      loss_b = loss_fn(_predict_b, label_b)\n",
        "      loss_c = loss_fn(_predict_c, label_c)\n",
        "      loss_d = loss_fn(_predict_d, label_d)\n",
        "      #loss_e = loss_fn(_predict_e, label_e)\n",
        "      total_loss = sum([loss_a, loss_b, loss_c, loss_d])\n",
        "      optimizer.zero_grad()\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss += total_loss.item()\n",
        "      f1_a = binary_f1_score(torch.flatten(_predict_a), torch.flatten(label_a), threshold=0.5)\n",
        "      f1_b = binary_f1_score(torch.flatten(_predict_b), torch.flatten(label_b), threshold=0.5)\n",
        "      f1_c = binary_f1_score(torch.flatten(_predict_c), torch.flatten(label_c), threshold=0.5)\n",
        "      f1_d = binary_f1_score(torch.flatten(_predict_d), torch.flatten(label_d), threshold=0.5)\n",
        "      current_f1 = ((f1_a + f1_b + f1_c + f1_d) / 4)\n",
        "      f1 += current_f1\n",
        "      count += 1\n",
        "      # print losses / score\n",
        "      if batch % 100 == 0: # print loss all 100 batches\n",
        "        size = len(dataloader.dataset)\n",
        "        #print(f\"F1 score: {current_f1}, Train loss: {total_loss.item():>7f}  [{batch*BATCH_SIZE:>5d}/{size:>5d}]\")\n",
        "\n",
        "    avg_loss = loss/count\n",
        "    avg_f1 = f1/count\n",
        "    model.train_losses.append(avg_loss)\n",
        "    print(f\"Train loss: {avg_loss}, Train f1: {avg_f1}\")\n",
        "    return\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    loss = 0\n",
        "    f1 = 0\n",
        "    count = 0\n",
        "    for batch, data in enumerate(dataloader):\n",
        "      tokens = data[0]\n",
        "      targets = data[1]\n",
        "      label_a = (data[2].to(device))\n",
        "      label_b = (data[3].to(device))\n",
        "      label_c = (data[4].to(device))\n",
        "      label_d = (data[5].to(device))\n",
        "      #label_e = (data[6].to(device))\n",
        "      _predict_a, _predict_b, _predict_c, _predict_d = model(tokens.to(device), targets.to(device))\n",
        "      # -> calc loss of all targets\n",
        "      #print(f\"{_predict_a.shape=}, {label_a.shape=}\")\n",
        "      loss_a = loss_fn(_predict_a, label_a) \n",
        "      loss_b = loss_fn(_predict_b, label_b)\n",
        "      loss_c = loss_fn(_predict_c, label_c)\n",
        "      loss_d = loss_fn(_predict_d, label_d)\n",
        "      #loss_e = loss_fn(_predict_e, label_e)\n",
        "      total_loss = loss_a.item() + loss_b.item() + loss_c.item() + loss_d.item()\n",
        "      loss += total_loss\n",
        "      f1_a = binary_f1_score(torch.flatten(_predict_a), torch.flatten(label_a), threshold=0.5)\n",
        "      f1_b = binary_f1_score(torch.flatten(_predict_b), torch.flatten(label_b), threshold=0.5)\n",
        "      f1_c = binary_f1_score(torch.flatten(_predict_c), torch.flatten(label_c), threshold=0.5)\n",
        "      f1_d = binary_f1_score(torch.flatten(_predict_d), torch.flatten(label_d), threshold=0.5)\n",
        "      current_f1 = ((f1_a + f1_b + f1_c + f1_d) / 4)\n",
        "      f1 += current_f1\n",
        "      count += 1\n",
        "      # print losses / score\n",
        "      if batch % 100 == 0: # print loss all 100 batches\n",
        "        size = len(dataloader.dataset)\n",
        "        #print(f\"F1 score: {current_f1}, Test loss: {total_loss:>7f}  [{batch:>5d}/{size:>5d}]\")\n",
        "\n",
        "    avg_loss = loss/count\n",
        "    avg_f1 = f1/count\n",
        "    model.test_losses.append(avg_loss)\n",
        "    print(f\"Test loss: {avg_loss}, Test f1: {avg_f1}\")\n",
        "    return"
      ],
      "metadata": {
        "id": "9dzdRr_o8NPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d52da8-94df-481b-e702-4376205a71f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.8/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torchtnt in /usr/local/lib/python3.8/dist-packages (from torcheval) (0.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torcheval) (4.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (2.9.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (5.9.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (1.13.0+cu116)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (2022.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (1.21.6)\n",
            "Requirement already satisfied: pyre-extensions in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (0.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from torchtnt->torcheval) (57.4.0)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.8/dist-packages (from pyre-extensions->torchtnt->torcheval) (0.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (2.25.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.3.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.51.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->torchtnt->torcheval) (0.38.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtnt->torcheval) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->torchtnt->torcheval) (5.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt->torcheval) (2022.12.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect->pyre-extensions->torchtnt->torcheval) (0.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->torchtnt->torcheval) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt->torcheval) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtnt->torcheval) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset model\n",
        "# TODO: rename to recipe_emebedding_model\n",
        "skipgram_model = SkipGramModel(vocab_size).to(device)"
      ],
      "metadata": {
        "id": "IP-EcWq_sIs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "lr = 2e-2\n",
        "total_epochs = 5\n",
        "optimizer = torch.optim.SGD(skipgram_model.parameters(), lr=lr)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "#loss_fn = torch.nn.MultiLabelSoftMarginLoss()\n",
        "\n",
        "# DEBUG\n",
        "#debug_train_dataloader= DataLoader(train_data[:100], batch_size = BATCH_SIZE)\n",
        "#debug_test_dataloader = DataLoader(test_data[:20], batch_size = BATCH_SIZE)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# copy to gpu\n",
        "for t in range(total_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, skipgram_model, loss_fn, optimizer)\n",
        "    test(test_dataloader, skipgram_model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl1SNGA784OQ",
        "outputId": "a88e10b5-2d4f-47d2-d61e-22d784d03591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 4.545210427439797, Train f1: 0.28852763772010803\n",
            "Test loss: 4.513850251033616, Test f1: 0.29117557406425476\n",
            "Epoch 2\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 4.528324329649716, Train f1: 0.2910614311695099\n",
            "Test loss: 4.5108686296197655, Test f1: 0.29177212715148926\n",
            "Epoch 3\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 4.525566234136187, Train f1: 0.291001558303833\n",
            "Test loss: 4.509673603201429, Test f1: 0.2909284234046936\n",
            "Epoch 4\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 4.524111932782985, Train f1: 0.29119494557380676\n",
            "Test loss: 4.508808388768767, Test f1: 0.29078802466392517\n",
            "Epoch 5\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 4.522982349146658, Train f1: 0.2913210988044739\n",
            "Test loss: 4.50845434051007, Test f1: 0.2915908694267273\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = [4.51385025, 4.510868629, 4.50967360, 4.50880838, 4.5084543]\n",
        "f1_scores = [0.291175, 0.291772, 0.290928, 0.290788, 0.291590]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.lineplot(data = f1_scores, ax=ax).set(title=\"Validation f1 score\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "ax.set_ylim(0.28,0.3)\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Eo6SHBRSZcWb",
        "outputId": "644c8a4d-50ad-4bf0-d67f-21f0526efabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# print metrics after final epoch"
      ],
      "metadata": {
        "id": "BkyxCXTmgCL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot losses\n",
        "epoch_losses = [x.cpu().item() for x in skipgram_model.test_losses]\n",
        "\n",
        "print(epoch_losses)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "fig = sns.lineplot(data = epoch_losses).set(title=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show(fig)\n",
        "\n",
        "print(skipgram_model.train_losses)"
      ],
      "metadata": {
        "id": "Tir6SdjTbxtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = next(iter(train_dataloader))[0]\n",
        "skipgram_model(test_input.to(\"cuda\"))"
      ],
      "metadata": {
        "id": "5f6B7KzqhCBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline model for comparison, using naive one-hot encoding representation for ingredients.**"
      ],
      "metadata": {
        "id": "Nh1zYHUNrok-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw_x51pCuveO"
      },
      "outputs": [],
      "source": [
        "# query input: user id (+ ratings)\n",
        "# prediction:  rating of other recipes\n",
        "# Create model\n",
        "device = \"cpu\"\n",
        "\n",
        "# Define model\n",
        "class RatingModel(nn.Module):\n",
        "    # Your code\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(8*2*batch_size, 32),  # 2 vector size 8 input (user, nutrition)\n",
        "            nn.ReLU(),  # Important between linear layers\n",
        "            nn.Linear(32, 32),  # Multiple stacked layers\n",
        "            nn.ReLU(),  \n",
        "            nn.Linear(32, batch_size) # output = 1 dimension, rating between 0 and 5\n",
        "        )\n",
        "\n",
        "    def forward(self, user, recipe):\n",
        "        query = torch.flatten(query)\n",
        "        doc = torch.flatten(doc)\n",
        "        tensor = torch.cat((query,doc),0)\n",
        "        logits = self.linear_relu_stack(tensor)\n",
        "        return logits\n",
        "\n",
        "model = RatingModel().to(device)\n",
        "model.double()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) #todo\n",
        "loss_fn = nn.CrossEntropyLoss() #good for classification (might as well consider mean squared error for continues rating prediction at interval [0-5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJdXIyjg2sI4"
      },
      "outputs": [],
      "source": [
        "# Implement data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "print(train_data[0])\n",
        "\n",
        "# for x, y in train_dataloader:\n",
        "#     print(f\"Shape of x: {x.shape} {x.dtype}\")\n",
        "#     print(f\"Shape of x: {y.shape} {y.dtype}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eEZakygnQSI"
      },
      "source": [
        "# 2) Generation of natural language meal preperation (reference preperation + meal) - input ingredient + recipe name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b62YPLYInq6l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be34ad8a3bb2474dafaf3f69d9d0a9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06984fcac5844aab950f911ac35e1e99",
              "IPY_MODEL_9aec8d632fa141e3b3f954cd8f0e3222",
              "IPY_MODEL_0b8f33c410404307b46a88ed655d74d1"
            ],
            "layout": "IPY_MODEL_d13f893541a241a3a93c4269f96dac79"
          }
        },
        "06984fcac5844aab950f911ac35e1e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fadffcbc9734373ad79679dca16c29f",
            "placeholder": "​",
            "style": "IPY_MODEL_38baaf5ebd2447f585a5f6738e394627",
            "value": "Downloading: 100%"
          }
        },
        "9aec8d632fa141e3b3f954cd8f0e3222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7041db6d6f574ca89075be0f71b2b1df",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a694f7f7f9447a68971aeb7f6a09f73",
            "value": 435779157
          }
        },
        "0b8f33c410404307b46a88ed655d74d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab4d22d300aa4fd1b98b12d97a70b3ff",
            "placeholder": "​",
            "style": "IPY_MODEL_53a58b43ed2e44d497fdfcf61215969a",
            "value": " 436M/436M [00:05&lt;00:00, 83.1MB/s]"
          }
        },
        "d13f893541a241a3a93c4269f96dac79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fadffcbc9734373ad79679dca16c29f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38baaf5ebd2447f585a5f6738e394627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7041db6d6f574ca89075be0f71b2b1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a694f7f7f9447a68971aeb7f6a09f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab4d22d300aa4fd1b98b12d97a70b3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a58b43ed2e44d497fdfcf61215969a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a19baf287040a1868d944e757c2cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48e0e74616014e1e87c0d205aeb933c5",
              "IPY_MODEL_24caabec4e624b04a93bc984945efffa",
              "IPY_MODEL_d01aa522966643d4a0b7cf867167a88c"
            ],
            "layout": "IPY_MODEL_b81d4dd85402471ab5b7cdcf0533faf6"
          }
        },
        "48e0e74616014e1e87c0d205aeb933c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8289f5617c74a34997b85788c149fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_9a01ff8d17594dac934b880712c4c240",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "24caabec4e624b04a93bc984945efffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e74ca252815d4b49bc2ffd069e144cef",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e428cadbd6ab433199895e7e4ed06e70",
            "value": 2
          }
        },
        "d01aa522966643d4a0b7cf867167a88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2f232d7c5842d3a45db83f0c6bc440",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd0ebf742ba4540a18a7f1e38b69d4c",
            "value": " 2/2 [00:01&lt;00:00,  1.84it/s]"
          }
        },
        "b81d4dd85402471ab5b7cdcf0533faf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d8289f5617c74a34997b85788c149fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a01ff8d17594dac934b880712c4c240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e74ca252815d4b49bc2ffd069e144cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e428cadbd6ab433199895e7e4ed06e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e2f232d7c5842d3a45db83f0c6bc440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd0ebf742ba4540a18a7f1e38b69d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a7da8f3c2c4c96989073084fd400ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dae486fa81464e33b43f6ae965bfb258",
              "IPY_MODEL_74955ed631504d39a37b1bba2f980e44",
              "IPY_MODEL_e7d4f2bd68644f23947d5c41734aa584"
            ],
            "layout": "IPY_MODEL_af62df57bfdd403e98601de97e68b2c9"
          }
        },
        "dae486fa81464e33b43f6ae965bfb258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2534d67632204e98bc326c6434a19d88",
            "placeholder": "​",
            "style": "IPY_MODEL_5bf7d29755f34ac49663164c34ef7f2b",
            "value": "Epoch 0:   0%"
          }
        },
        "74955ed631504d39a37b1bba2f980e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361083fa1b3f4def9379e5d1cf479ac4",
            "max": 750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65fbdd3ddfb84bed92c6e4660acd75bd",
            "value": 0
          }
        },
        "e7d4f2bd68644f23947d5c41734aa584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fb048f27f5414b81355068a6b90348",
            "placeholder": "​",
            "style": "IPY_MODEL_0f77db47c1e24211b3da5c3cd79b1fc2",
            "value": " 0/750 [00:00&lt;?, ?it/s]"
          }
        },
        "af62df57bfdd403e98601de97e68b2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2534d67632204e98bc326c6434a19d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf7d29755f34ac49663164c34ef7f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361083fa1b3f4def9379e5d1cf479ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fbdd3ddfb84bed92c6e4660acd75bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57fb048f27f5414b81355068a6b90348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f77db47c1e24211b3da5c3cd79b1fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}